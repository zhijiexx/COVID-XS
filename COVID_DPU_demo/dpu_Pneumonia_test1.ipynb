{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPU example: Pneumonia Detection Model - Pnem1\n",
    "\n",
    "This notebooks shows an example of DPU applications. The application,\n",
    "as well as the DPU IP, is pulled from the official \n",
    "[Vitis AI Github Repository](https://github.com/Xilinx/Vitis-AI).\n",
    "For more information, please refer to the \n",
    "[Xilinx Vitis AI page](https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html).\n",
    "\n",
    "In this notebook, we will show how to use **Python API** to run DPU tasks.\n",
    "\n",
    "## 1. Prepare the overlay\n",
    "We will download the overlay onto the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"../dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VAI package has been installed onto your board. There are multiple\n",
    "binaries installed; for example, you can check the current DPU status using\n",
    "`dexplorer`. You should be able to see reasonable values from the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!dexplorer -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dexplorer -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compiled quantized model may have different kernel names depending on the DPU architectures.\n",
    "This piece of information can usually be found when compiling the `*.elf` model file.\n",
    "\n",
    "The `*.elf` model will be compiled into a shared object file; that file has to be copied to your \n",
    "library path for DNNDK inference.\n",
    "\n",
    "By default, the naming convention for model files is:\n",
    "\n",
    "* Model `*.elf` file: `dpu_<kernel_name>[_0].elf`\n",
    "* Shared object `*.so` file: `libdpumodel<kernel_name>.elf`\n",
    "\n",
    "All of these steps are handled by `load_model()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"./models/dpu_Pnem1_0.elf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Python program\n",
    "\n",
    "We will use DNNDK's Python API to run DPU tasks.\n",
    "In this example, we will set the number of iterations to 500, meaning \n",
    "that a single picture will be taken and classified 500 times.\n",
    "Users can adjust this value if they want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dnndk import n2cube\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "from pynq_dpu import dputils  \n",
    "\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Model for 150x150 image \n",
    "\n",
    "KERNEL_CONV = \"Pnem1_0\"  \n",
    "KERNEL_CONV_INPUT = \"conv2d_1_convolution\"\n",
    "KERNEL_FC_OUTPUT = \"dense_out_MatMul\" \n",
    "\n",
    "img_dims=150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a picture from the image folder and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Count=30\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    " \n",
    "image_folder = \"./data/samples/\"    \n",
    "listimage = [i for i in os.listdir(image_folder) if \"NORMAL\" in i or \"PNEUMONIA\" in i ]\n",
    "print(\"Sample Image Count={}\".format(len(listimage)))  \n",
    "imfile = listimage[0]\n",
    "with open(\"./labels.txt\", \"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also open and initialize the DPU device. We will create a DPU kernel and reuse it.\n",
    "Throughout the entire notebook, we don't have to redo this step.\n",
    "\n",
    "**Note**: if you open and close DPU multiple times, the Jupyter kernel might die;\n",
    "this is because the current DNNDK implementation requires bitstream to be downloaded by XRT,\n",
    "which is not supported by `pynq` package. Hence we encourage users to stay with\n",
    "one single DPU session, both for program robustness and higher performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2cube.dpuOpen() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = n2cube.dpuLoadKernel(KERNEL_CONV) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single execution\n",
    "We define a function that will use the DPU to make a prediction on an input \n",
    "image and provide a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(imfile):\n",
    "    task = n2cube.dpuCreateTask(kernel, 0)\n",
    "\n",
    "    path = os.path.join(image_folder, imfile)\n",
    "    img = cv2.imread(path) \n",
    "    img = cv2.resize(img, (img_dims, img_dims))\n",
    "    img = img.astype(np.float32)\n",
    "    img = (img/255.0) \n",
    "        \n",
    "    \"\"\"Get input Tensor\"\"\"\n",
    "    tensor = n2cube.dpuGetInputTensor(task, KERNEL_CONV_INPUT)\n",
    "    input_len = n2cube.dpuGetInputTensorSize(task, KERNEL_CONV_INPUT)   \n",
    "    #print(input_len)\n",
    "        \n",
    "    \"\"\"Set input Tesor\"\"\"\n",
    "    n2cube.dpuSetInputTensorInHWCFP32(task, KERNEL_CONV_INPUT, img, input_len)\n",
    "\n",
    "    \"\"\"Model run on DPU\"\"\"\n",
    "    n2cube.dpuRunTask(task)\n",
    "        \n",
    "    \"\"\"Get the output tensor size from FC output\"\"\"\n",
    "    size = n2cube.dpuGetOutputTensorSize(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "    \"\"\"Get the output tensor channel from FC output\"\"\"\n",
    "    channel = n2cube.dpuGetOutputTensorChannel(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "    softmax = np.zeros(size,dtype=np.float32)\n",
    "\n",
    "    \"\"\"Get FC result\"\"\"\n",
    "    conf = n2cube.dpuGetOutputTensorAddress(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "    \"\"\"Get output scale of FC\"\"\"\n",
    "    outputScale = n2cube.dpuGetOutputTensorScale(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "    \"\"\"Run softmax\"\"\"\n",
    "    softmax = n2cube.dpuRunSoftmax(conf, channel, size // channel, outputScale)\n",
    "     \n",
    "    #print(\"size=\", size)\n",
    "    #print(\"channel=\", channel)\n",
    "    #print(\"outputScale=\", outputScale)\n",
    "    print(\"softmax =\", softmax)\n",
    "\n",
    "    n2cube.dpuDestroyTask(task)\n",
    "    \n",
    "    return lines[np.argmax(softmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: test with only 10 random X-Ray images\n",
      "0  PNEUMONIA_fe1289af-87c8-49c6-800c-1e87b2296df8.jpg\n",
      "softmax = [ 0.00460957  0.99539047]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "1  NORMAL_8d3d0ba6-799d-4874-a804-75a4c0cf4ae6.jpg\n",
      "softmax = [ 0.46879062  0.53120941]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "2  PNEUMONIA_849217ad-5cb2-4a87-9796-420b69722b14.jpg\n",
      "softmax = [ 0.04742587  0.95257413]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "3  NORMAL_8cfcc69b-d659-4888-8551-790891d8568e.jpg\n",
      "softmax = [ 0.99330717  0.00669285]\n",
      "Class label: NORMAL\n",
      "\n",
      "4  PNEUMONIA_852156be-0aab-4dc7-95d6-eda950096d0f.jpg\n",
      "softmax = [ 0.1066906   0.89330941]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "5  PNEUMONIA_84032d11-9143-45a2-b3e9-955f9dc4b497.jpg\n",
      "softmax = [  3.12019147e-05   9.99968827e-01]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "6  NORMAL_fc4cd37e-7bae-425d-9465-bfdd0ecf0b63.jpg\n",
      "softmax = [ 0.96267313  0.03732689]\n",
      "Class label: NORMAL\n",
      "\n",
      "7  PNEUMONIA_fef7b294-017c-4491-9e57-119086855785.jpg\n",
      "softmax = [  8.48110431e-05   9.99915183e-01]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "8  PNEUMONIA_85727853-cb45-478d-a517-a0f0c85d0eb5.jpg\n",
      "softmax = [  2.61190318e-04   9.99738812e-01]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "9  NORMAL_8c62b364-84be-4c83-9c3a-43df335a1978.jpg\n",
      "softmax = [ 0.46879059  0.53120935]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "10  NORMAL_fc6599d7-fa85-4361-b26e-e51f2375ecf2.jpg\n",
      "softmax = [ 0.59266663  0.4073334 ]\n",
      "Class label: NORMAL\n",
      "\n",
      "11  NORMAL_8d091d33-6dfc-431e-b459-995016771709.jpg\n",
      "softmax = [ 0.99029154  0.00970848]\n",
      "Class label: NORMAL\n",
      "\n",
      "12  PNEUMONIA_fdfce1ff-203e-4b23-a360-3803558a7f7a.jpg\n",
      "softmax = [ 0.00407014  0.9959299 ]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "13  NORMAL_fe8460ea-9f61-4f29-b315-ffb5c01f4eef.jpg\n",
      "softmax = [ 0.98409361  0.01590639]\n",
      "Class label: NORMAL\n",
      "\n",
      "14  PNEUMONIA_fe2e6108-895f-4469-8712-7965544dd47c.jpg\n",
      "softmax = [ 0.00591107  0.99408895]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "15  NORMAL_8c82ad94-205c-435a-a510-e4be16cf5657.jpg\n",
      "softmax = [ 0.754915    0.24508502]\n",
      "Class label: NORMAL\n",
      "\n",
      "16  PNEUMONIA_863a923a-3906-42d3-92db-76c900091fce.jpg\n",
      "softmax = [ 0.01098694  0.98901308]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "17  PNEUMONIA_844ac956-e1e2-4f27-b58c-390d6405c3a0.jpg\n",
      "softmax = [ 0.00669285  0.99330717]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "18  NORMAL_fca8b18a-9851-4115-af53-6d7540820888.jpg\n",
      "softmax = [ 0.966914    0.03308598]\n",
      "Class label: NORMAL\n",
      "\n",
      "19  NORMAL_8c4421ee-115a-472c-b3cd-48c6c3b8e42b.jpg\n",
      "softmax = [ 0.0675467   0.93245333]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "20  NORMAL_fe02ac25-6a2a-4c6b-909e-c8a9c7c67f53.jpg\n",
      "softmax = [ 0.98756832  0.01243165]\n",
      "Class label: NORMAL\n",
      "\n",
      "21  PNEUMONIA_86e9848d-dd57-48b4-b016-5b1447fdbd58.jpg\n",
      "softmax = [  6.60521473e-05   9.99933958e-01]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "22  NORMAL_fc35980f-918e-4f10-b3e4-d4202394e7da.jpg\n",
      "softmax = [ 0.9149009   0.08509904]\n",
      "Class label: NORMAL\n",
      "\n",
      "23  NORMAL_8d768b9e-92cb-4343-9a2a-20ce3d137695.jpg\n",
      "softmax = [ 0.59266663  0.4073334 ]\n",
      "Class label: NORMAL\n",
      "\n",
      "24  NORMAL_fcbe3898-4d24-402a-a64a-f11c95d23235.jpg\n",
      "softmax = [ 0.99142247  0.00857748]\n",
      "Class label: NORMAL\n",
      "\n",
      "25  PNEUMONIA_02c34d5b-16e9-412e-a385-ccd8cbceae16.jpg\n",
      "softmax = [  2.30506717e-04   9.99769509e-01]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "26  PNEUMONIA_8489c930-19a8-4895-9211-4efd3d38ae58.jpg\n",
      "softmax = [ 0.89330941  0.10669059]\n",
      "Class label: NORMAL\n",
      "\n",
      "27  PNEUMONIA_fcf5cd90-1a5d-4e45-925e-ff82dcbdc0ad.jpg\n",
      "softmax = [ 0.0035936   0.99640644]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "28  PNEUMONIA_fcd6452c-680d-40a6-9fc6-1793eb3ca0a8.jpg\n",
      "softmax = [ 0.00150118  0.9984988 ]\n",
      "Class label: PNEUMONIA\n",
      "\n",
      "29  NORMAL_8c2b6caa-41cd-45c0-95f0-de71c3e9186b.jpg\n",
      "softmax = [ 0.77729988  0.22270013]\n",
      "Class label: NORMAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"INFO: test with only 10 random X-Ray images\")\n",
    "sublist = listimage[0:10]\n",
    "i = 0\n",
    "for img in listimage:\n",
    "    print(\"{}  {}\".format(i, img))\n",
    "    i = i + 1 \n",
    "    label = predict_label(img)\n",
    "    print('Class label: {}'.format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple executions\n",
    "After we have verified the correctness of a single execution, we can\n",
    "try multiple executions and measure the throughput in Frames Per Second (FPS).\n",
    "\n",
    "Let's define a function that processes a single image in multiple iterations. \n",
    "The parameters are:\n",
    "* `kernel`: DPU kernel.\n",
    "* `img`: image to be classified.\n",
    "* `count` : test rounds count.\n",
    "\n",
    "The number of iterations is defined as `num_iterations` in previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(image_folder, imfile)\n",
    "img = cv2.imread(path) \n",
    "img = cv2.resize(img, (img_dims, img_dims))\n",
    "img = img.astype(np.float32)\n",
    "img = (img/255.0) \n",
    "\n",
    "def run_dpu_task(kernel, img, count):\n",
    "    task = n2cube.dpuCreateTask(kernel, 0)\n",
    "    \n",
    "    count = 0\n",
    "    while count < num_iterations:\n",
    "           \n",
    "        \"\"\"Get input Tensor\"\"\"\n",
    "        tensor = n2cube.dpuGetInputTensor(task, KERNEL_CONV_INPUT)\n",
    "        input_len = n2cube.dpuGetInputTensorSize(task, KERNEL_CONV_INPUT)   \n",
    "        \n",
    "        \"\"\"Set input Tesor\"\"\"\n",
    "        n2cube.dpuSetInputTensorInHWCFP32(task, KERNEL_CONV_INPUT, img, input_len)\n",
    "\n",
    "        \"\"\"Model run on DPU\"\"\"\n",
    "        n2cube.dpuRunTask(task)\n",
    "        \n",
    "        \"\"\"Get the output tensor size from FC output\"\"\"\n",
    "        size = n2cube.dpuGetOutputTensorSize(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Get the output tensor channel from FC output\"\"\"\n",
    "        channel = n2cube.dpuGetOutputTensorChannel(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        softmax = np.zeros(size,dtype=np.float32)\n",
    "\n",
    "        \"\"\"Get FC result\"\"\"\n",
    "        conf = n2cube.dpuGetOutputTensorAddress(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Get output scale of FC\"\"\"\n",
    "        outputScale = n2cube.dpuGetOutputTensorScale(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Run softmax\"\"\"\n",
    "        softmax = n2cube.dpuRunSoftmax(conf, channel, size // channel, outputScale)\n",
    "\n",
    "        lock.acquire()\n",
    "        count = count + threadnum\n",
    "        lock.release()\n",
    "\n",
    "    n2cube.dpuDestroyTask(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to run the batch processing and print out DPU throughput.\n",
    "Users can change the `image_folder` to point to other picture locations.\n",
    "We will use the previously defined and classified image `img` and process it for\n",
    "`num_interations` times.\n",
    "\n",
    "In this example, we will just use a single thread.\n",
    "\n",
    "The following cell may take a while to run. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.09 FPS\n"
     ]
    }
   ],
   "source": [
    "threadAll = []\n",
    "threadnum = 1\n",
    "num_iterations = 500\n",
    "start = time.time()\n",
    "\n",
    "for i in range(threadnum):\n",
    "    t1 = threading.Thread(target=run_dpu_task, args=(kernel, img, i))\n",
    "    threadAll.append(t1)\n",
    "for x in threadAll:\n",
    "    x.start()\n",
    "for x in threadAll:\n",
    "    x.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "fps = float(num_iterations/(end-start))\n",
    "print(\"%.2f FPS\" % fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.20 FPS\n"
     ]
    }
   ],
   "source": [
    "threadAll = []\n",
    "threadnum = 4\n",
    "num_iterations = 500\n",
    "start = time.time()\n",
    "\n",
    "for i in range(threadnum):\n",
    "    t1 = threading.Thread(target=run_dpu_task, args=(kernel, img, i))\n",
    "    threadAll.append(t1)\n",
    "for x in threadAll:\n",
    "    x.start()\n",
    "for x in threadAll:\n",
    "    x.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "fps = float(num_iterations/(end-start))\n",
    "print(\"%.2f FPS\" % fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.35 FPS\n"
     ]
    }
   ],
   "source": [
    "threadAll = []\n",
    "threadnum = 8\n",
    "num_iterations = 500\n",
    "start = time.time()\n",
    "\n",
    "for i in range(threadnum):\n",
    "    t1 = threading.Thread(target=run_dpu_task, args=(kernel, img, i))\n",
    "    threadAll.append(t1)\n",
    "for x in threadAll:\n",
    "    x.start()\n",
    "for x in threadAll:\n",
    "    x.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "fps = float(num_iterations/(end-start))\n",
    "print(\"%.2f FPS\" % fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tasks(kernel):\n",
    "    task = n2cube.dpuCreateTask(kernel, 0)\n",
    "    \n",
    "    o_count = [0, 0, 0]\n",
    "    p_count = [0, 0, 0]\n",
    "     \n",
    "    image_folder = \"./data/images/\"  \n",
    "    listimage = [i for i in os.listdir(image_folder) if \"NORMAL\" in i or \"PNEUMONIA\" in i ] \n",
    "    num_iterations=len(listimage)\n",
    "    print(\"Total Test Image Count={}\".format(num_iterations)) \n",
    "    count = 0\n",
    "\n",
    "    with open(\"./labels.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    print(\"====================== Start: Test results with 1000 X-Rays ==================\")\n",
    "    while count < num_iterations:\n",
    "        imfile = listimage[count]\n",
    "        path = os.path.join(image_folder, imfile)\n",
    "        img = cv2.imread(path) \n",
    "        img = cv2.resize(img, (img_dims, img_dims))\n",
    "        img = img.astype(np.float32)\n",
    "        img = (img/255.0) \n",
    "        \n",
    "        \"\"\"Get input Tensor\"\"\"\n",
    "        tensor = n2cube.dpuGetInputTensor(task, KERNEL_CONV_INPUT)\n",
    "        input_len = n2cube.dpuGetInputTensorSize(task, KERNEL_CONV_INPUT)   \n",
    "        #print(input_len)\n",
    "        \n",
    "        \"\"\"Set input Tesor\"\"\"\n",
    "        n2cube.dpuSetInputTensorInHWCFP32(task, KERNEL_CONV_INPUT, img, input_len)\n",
    "\n",
    "        \"\"\"Model run on DPU\"\"\"\n",
    "        n2cube.dpuRunTask(task)\n",
    "        \n",
    "        \"\"\"Get the output tensor size from FC output\"\"\"\n",
    "        size = n2cube.dpuGetOutputTensorSize(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Get the output tensor channel from FC output\"\"\"\n",
    "        channel = n2cube.dpuGetOutputTensorChannel(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        softmax = np.zeros(size,dtype=np.float32)\n",
    "\n",
    "        \"\"\"Get FC result\"\"\"\n",
    "        conf = n2cube.dpuGetOutputTensorAddress(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Get output scale of FC\"\"\"\n",
    "        outputScale = n2cube.dpuGetOutputTensorScale(task, KERNEL_FC_OUTPUT)\n",
    "\n",
    "        \"\"\"Run softmax\"\"\"\n",
    "        softmax = n2cube.dpuRunSoftmax(conf, channel, size // channel, outputScale)\n",
    "\n",
    "        expected = False\n",
    "        if imfile[0] == 'N':  \n",
    "            o_count[0] = o_count[0] + 1 \n",
    "        elif imfile[0] == 'P':\n",
    "            o_count[1] = o_count[1] + 1  \n",
    "        else:\n",
    "            print(\"ERROR: Invalid file tag in {}\".format(imfile))\n",
    "        \n",
    "        label = np.argmax(softmax)\n",
    "        p_count[label] = p_count[label] + 1 \n",
    "        slabel = lines[label]   \n",
    "        count = count + 1  \n",
    "    print(\"Actual #(NORMAL, PNEUMONIA)= ({}, {})\". format(o_count[0], o_count[1]))\n",
    "    print(\"Predic #(NORMAL, PNEUMONIA)= ({}, {})\". format(p_count[0], p_count[1]))\n",
    "    print(\"Percentage Prediction (NORMAL, PNEUMONIA)=({}, {})\".format((p_count[0]*100)/o_count[0], (p_count[1]*100)/o_count[1])) \n",
    "    n2cube.dpuDestroyTask(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Test Image Count=1000\n",
      "====================== Start: Test results with 1000 X-Rays ==================\n",
      "Actual #(NORMAL, PNEUMONIA)= (500, 500)\n",
      "Predic #(NORMAL, PNEUMONIA)= (519, 481)\n",
      "Percentage Prediction (NORMAL, PNEUMONIA)=(103.8, 96.2)\n"
     ]
    }
   ],
   "source": [
    "run_tasks(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "Finally, when you are done with the DPU experiments, remember to destroy the kernel and close the DPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2cube.dpuDestroyKernel(kernel)\n",
    "n2cube.dpuClose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
